from aiogram import types
import datetime, configparser, webparser


#base
with open('filter.txt', 'r', encoding="utf-8") as file:
	words = file.read().split()


ru_country = {'Ñ€Ğ¾ÑÑĞ¸Ñ':'russia', 'ÑÑˆĞ°':'usa', 'Ğ³ĞµÑ€Ğ¼Ğ°Ğ½Ğ¸Ñ':'germany', 'Ğ¸Ñ‚Ğ°Ğ»Ğ¸Ñ':'italy', 'ĞºĞ¸Ñ‚Ğ°Ğ¹':'china',
'ÑĞ¿Ğ¾Ğ½Ğ¸Ñ':'japan', 'Ğ¿Ğ¾Ğ»ÑŒÑˆĞ°':'poland', 'ÑƒĞºÑ€Ğ°Ğ¸Ğ½Ğ°':'ukraine', 'Ğ²ĞµĞ»Ğ¸ĞºĞ¾Ğ±Ñ€Ğ¸Ñ‚Ğ°Ğ½Ğ¸Ñ':'uk', 'Ğ°Ñ„Ğ³Ğ°Ğ½Ğ¸ÑÑ‚Ğ°Ğ½':'afghanistan',
'Ğ½Ğ¾Ğ²Ğ°Ñ Ğ³Ğ²Ğ¸Ğ½ĞµÑ':'Papua New Guinea', 'Ğ¸ÑĞ¿Ğ°Ğ½Ğ¸Ñ':'spain', 'Ñ„Ñ€Ğ°Ğ½Ñ†Ğ¸Ñ':'france', 'Ğ±Ñ€Ğ°Ğ·Ğ¸Ğ»Ğ¸Ñ':'brazil', 'Ñ‚ÑƒÑ€ĞºĞ¼ĞµĞ½Ğ¸Ñ':'turkey',
'Ğ¸Ñ€Ğ°Ğ½':'iran', 'Ğ¸Ğ½Ğ´Ğ¸Ñ':'india', 'ĞºĞ°Ğ½Ğ°Ğ´Ğ°':'canada', 'Ğ¿ĞµÑ€Ñƒ':'peru', 'Ğ±ĞµĞ»ÑŒĞ³Ğ¸Ñ':'belgium',
'Ğ½Ğ¸Ğ´ĞµĞ»Ğ°Ğ½Ğ´Ñ‹':'netherlands', 'ÑĞ°ÑƒĞ´Ğ¾Ğ²ÑĞºĞ°Ñ Ğ°Ñ€Ğ°Ğ²Ğ¸Ñ':'saudi arabia', 'Ğ¼ĞµĞºÑĞ¸ĞºĞ°':'mexico', 'Ğ¿Ğ°ĞºĞ¸ÑÑ‚Ğ°Ğ½':'pakistan', 'ÑˆĞ²ĞµĞ¹Ñ†Ğ°Ñ€Ğ¸Ñ':'switzerland',
'Ñ‡Ğ¸Ğ»Ğ¸':'chile', 'ÑĞºĞ²Ğ°Ğ´Ğ¾Ñ€':'ecuador', 'Ğ¿Ğ¾Ñ€Ñ‚ÑƒĞ³Ğ°Ğ»Ğ¸Ñ':'portugal', 'Ğ±ĞµĞ»Ğ°Ñ€ÑƒÑÑŒ':'belarus'}


db = {}


#keyboards

main_k = types.ReplyKeyboardMarkup(resize_keyboard = True)

main_k.add('Ğ£Ğ·Ğ½Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ ğŸ“Š')
main_k.add('Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ’ĞĞ— ğŸ˜·')
main_k.add('Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ¿Ñ€Ğ¾ÑĞºÑ‚Ğµ')


static_k = types.ReplyKeyboardMarkup(resize_keyboard = True)

static_k.add('Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ² Ğ Ğ¾ÑÑĞ¸Ğ¸ ğŸ‡·ğŸ‡º')
static_k.add('Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ² Ğ¼Ğ¸Ñ€Ğµ ğŸŒ')
static_k.add('Ğ£Ğ·Ğ½Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ² Ğ»ÑĞ±Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğµ')
static_k.add('Ğ’ĞµÑ€Ğ½ÑƒÑ‚ÑŒÑÑ Ğº Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğ¼Ñƒ Ğ¼ĞµĞ½Ñ ğŸ”„')


info_k = types.ReplyKeyboardMarkup(resize_keyboard = True)

info_k.add('Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼Ñ‹Ğµ Ñ€ĞµÑÑƒÑ€ÑÑ‹')
info_k.add('Ğ’ĞµÑ€Ğ½ÑƒÑ‚ÑŒÑÑ Ğº Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğ¼Ñƒ Ğ¼ĞµĞ½Ñ ğŸ”„')


find_k = types.ReplyKeyboardMarkup(resize_keyboard = True)

find_k.add('Ğ’ĞµÑ€Ğ½ÑƒÑ‚ÑŒÑÑ Ğº Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğ¼Ñƒ Ğ¼ĞµĞ½Ñ ğŸ”„')

z_k = types.ReplyKeyboardMarkup(True)


date = ""


# functions

def get_bot_token()->str:
    cfg = configparser.ConfigParser()
    cfg.read("config.ini")
    return cfg["bot_data"]["token"]


def word_filter(text:str)->bool:
	for word_on_message in text.lower().split():
		if word_on_message in words:
			return True
	return False


def update_data():
	global db, date
	date = datetime.datetime.today().strftime('%d.%m')
	db = {}
	data = webparser.get_data()
	for country in data:
		base = data[country]
		country = base["country"]
		population = base["population"]
		all = base["total_cases"]
		active = base["active_cases"]
		recover = base["total_recovered"]
		death = base["total_deaths"]
		new_case = base["new_cases"]
		new_death = base["new_deaths"]
		new_recover = base["new_recovered"]
		db[country.lower()] = [country, population, all, active, recover, death, new_case, new_recover, new_death]


def get_data(country:str, text:str)->str:
	data = db[country.lower()]
	if text.lower() in ["world", "Ğ¼Ğ¸Ñ€"] or country in ["world", "Ğ¼Ğ¸Ñ€"]:
		return f"Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ² Ğ¼Ğ¸Ñ€Ğµ ğŸŒ Ğ½Ğ° {date}\n\nĞ’ÑĞµĞ³Ğ¾ Ğ·Ğ°Ñ€Ğ°Ğ·Ğ¸Ğ»Ğ¸ÑÑŒ ğŸ˜·: {data[2]}\nĞ¡ĞµĞ¹Ñ‡Ğ°Ñ Ğ±Ğ¾Ğ»ĞµÑÑ‚ ğŸ˜·: {data[3]}\nĞ’Ñ‹Ğ·Ğ´Ğ¾Ğ²ĞµĞ»Ğ¸ âœ…: {data[4]}\nĞ£Ğ¼ĞµÑ€Ğ»Ğ¸ ğŸ’€: {data[5]}\n\nĞ—Ğ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 24 Ñ‡Ğ°ÑĞ° ğŸ•“\nĞ—Ğ°Ğ±Ğ¾Ğ»ĞµĞ»Ğ¸ ğŸ˜·: {data[6]}\nĞ’Ñ‹Ğ·Ğ´Ğ¾Ğ²ĞµĞ»Ğ¸ âœ…: {data[7]}\nĞ£Ğ¼ĞµÑ€Ğ»Ğ¸ ğŸ’€: {data[8]}"
	if text.lower() in ["russia", "Ñ€Ğ¾ÑÑĞ¸Ñ"]:
		text = 'Ğ Ğ¾ÑÑĞ¸Ğ¸ ğŸ‡·ğŸ‡º'
	return f"Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ² {text.title()} Ğ½Ğ° {date}\n\nĞĞ°ÑĞµĞ»ĞµĞ½Ğ¸Ğµ {data[1]} Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº\n\nĞ’ÑĞµĞ³Ğ¾ Ğ·Ğ°Ñ€Ğ°Ğ·Ğ¸Ğ»Ğ¸ÑÑŒ ğŸ˜·: {data[2]}\nĞ¡ĞµĞ¹Ñ‡Ğ°Ñ Ğ±Ğ¾Ğ»ĞµÑÑ‚ ğŸ˜·: {data[3]}\nĞ’Ñ‹Ğ·Ğ´Ğ¾Ğ²ĞµĞ»Ğ¸ âœ…: {data[4]}\nĞ£Ğ¼ĞµÑ€Ğ»Ğ¸ ğŸ’€: {data[5]}\n\nĞ—Ğ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 24 Ñ‡Ğ°ÑĞ° ğŸ•“\nĞ—Ğ°Ğ±Ğ¾Ğ»ĞµĞ»Ğ¸ ğŸ˜·: {data[6]}\nĞ’Ñ‹Ğ·Ğ´Ğ¾Ğ²ĞµĞ»Ğ¸ âœ…: {data[7]}\nĞ£Ğ¼ĞµÑ€Ğ»Ğ¸ ğŸ’€: {data[8]}"
